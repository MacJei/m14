{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create SparkSession\n",
    "2. Read tabular datasets\n",
    "3. Dataframe API: SQL Projections and Filters\n",
    "4. SQL API\n",
    "5. Joins and Repartitions\n",
    "6. Aggregations\n",
    "7. Custom UDFs\n",
    "8. Fancy stuff: working with time\n",
    "9. Window functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=2, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+hadoop2.7\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4c0b5a7860>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c14346f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.plot(range(10), range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.Builder().getOrCreate()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_config = SparkConf().setMaster(\"local[*]\").setAppName(\"Spark SQL overview\")\n",
    "spark = SparkSession.Builder().config(conf=spark_config).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hive.metastore.warehouse.dir', 'file:/home/jovyan/spark-warehouse'),\n",
       " ('spark.driver.host', '172.17.0.2'),\n",
       " ('spark.driver.port', '34171'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.app.id', 'local-1597088678730'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.name', 'Spark SQL overview')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark._sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Dataset (Movielens-100k Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline\n",
    "\n",
    "```python\n",
    "spark.read \\\n",
    "     .format(...) \\\n",
    "     .option(key, value) \\\n",
    "     .option(key, value) \\\n",
    "     .load(path)\n",
    "```\n",
    "\n",
    "Data source: https://grouplens.org/datasets/movielens/100k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|24|M|technician|85711\r\n",
      "2|53|F|other|94043\r\n",
      "3|23|M|writer|32067\r\n",
      "4|24|M|technician|43537\r\n",
      "5|33|F|other|15213\r\n",
      "6|42|M|executive|98101\r\n",
      "7|57|M|administrator|91344\r\n",
      "8|36|M|administrator|05201\r\n",
      "9|29|M|student|01002\r\n",
      "10|53|M|lawyer|90703\r\n"
     ]
    }
   ],
   "source": [
    "! head ml-100k/u.user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A: what is \"format\", what are the \"options\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.33 ms, sys: 3.83 ms, total: 6.15 ms\n",
      "Wall time: 6.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"sep\", \"|\")\n",
    "    .load(\"ml-100k/u.user\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+----------+-----+\n",
      "|_c0|_c1|_c2|       _c3|  _c4|\n",
      "+---+---+---+----------+-----+\n",
      "|  1| 24|  M|technician|85711|\n",
      "+---+---+---+----------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='1', _c1='24', _c2='M', _c3='technician', _c4='85711'),\n",
       " Row(_c0='2', _c1='53', _c2='F', _c3='other', _c4='94043'),\n",
       " Row(_c0='3', _c1='23', _c2='M', _c3='writer', _c4='32067'),\n",
       " Row(_c0='4', _c1='24', _c2='M', _c3='technician', _c4='43537'),\n",
       " Row(_c0='5', _c1='33', _c2='F', _c3='other', _c4='15213')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If there is a table, then there should be a schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType(fields=[\n",
    "    types.StructField(\"user_id\", types.IntegerType()),\n",
    "    types.StructField(\"age\", types.IntegerType()),\n",
    "    types.StructField(\"gender\", types.StringType()),\n",
    "    types.StructField(\"occupation\", types.StringType()),\n",
    "    types.StructField(\"zip\", types.IntegerType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = (\n",
    "    spark.read\n",
    "    .schema(schema)\n",
    "    .format(\"csv\")\n",
    "    .option(\"sep\", \"|\")\n",
    "    .load(\"ml-100k/u.user\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, age: int, gender: string, occupation: string, zip: int]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- zip: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+-----+\n",
      "|user_id|age|gender|occupation|  zip|\n",
      "+-------+---+------+----------+-----+\n",
      "|      1| 24|     M|technician|85711|\n",
      "|      2| 53|     F|     other|94043|\n",
      "|      3| 23|     M|    writer|32067|\n",
      "|      4| 24|     M|technician|43537|\n",
      "|      5| 33|     F|     other|15213|\n",
      "+-------+---+------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following functionality is only available in Hadoop cluster installation\n",
    "# user_df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final version of reading Pipeline\n",
    "\n",
    "```python\n",
    "spark.read \\\n",
    "     .schema(...) \\\n",
    "     .format(...) \\\n",
    "     .option(key, value) \\\n",
    "     .option(key, value) \\\n",
    "     .load(path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenient Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = spark.read.csv(\"ml-100k/u.user\", schema=schema, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+-----+\n",
      "|user_id|age|gender|occupation|  zip|\n",
      "+-------+---+------+----------+-----+\n",
      "|      1| 24|     M|technician|85711|\n",
      "|      2| 53|     F|     other|94043|\n",
      "+-------+---+------+----------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tons of data sources with a unified API!\n",
    "+ CSV\n",
    "+ JSON\n",
    "+ Hive\n",
    "+ HBase\n",
    "+ Cassandra\n",
    "+ MySQL\n",
    "+ PostgreSQL\n",
    "+ Parquet\n",
    "+ ORC\n",
    "+ Kafka\n",
    "+ ElasticSearch\n",
    "+ Amazon S3\n",
    "+ ...and more through custom connectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs dataset: https://drive.google.com/drive/u/0/folders/1newx8_j2QU49dI8ogv-eWhvOylLpx7BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.49.147.163\t20140101014611\thttp://news.rambler.ru/3105700\t378\t431\tSafari/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;)\r",
      "\r\n",
      "197.72.248.141\t20140101020306\thttp://news.mail.ru/6344933\t1412\t203\tSafari/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729;\r",
      "\r\n",
      "33.49.147.163\t20140101023103\thttp://lenta.ru/4303000\t1189\t451\tChrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0)\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! head -3 logsM.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_schema = types.StructType(fields=[\n",
    "    types.StructField(\"ip\", types.StringType()),\n",
    "    types.StructField(\"timestamp\", types.LongType()),\n",
    "    types.StructField(\"url\", types.StringType()),\n",
    "    types.StructField(\"size\", types.IntegerType()),\n",
    "    types.StructField(\"code\", types.IntegerType()),\n",
    "    types.StructField(\"ua\", types.StringType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = spark.read.csv(\"logsM.txt\", sep=\"\\t\", schema=log_schema).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ip: string, timestamp: bigint, url: string, size: int, code: int, ua: string]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = log_df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+---------------------------+----+----+-------------------------------------------------------------------------------------------------------------+\n",
      "|ip            |timestamp     |url                        |size|code|ua                                                                                                           |\n",
      "+--------------+--------------+---------------------------+----+----+-------------------------------------------------------------------------------------------------------------+\n",
      "|197.72.248.141|20140101020306|http://news.mail.ru/6344933|1412|203 |Safari/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729;|\n",
      "|222.131.187.37|20140101033837|http://news.mail.ru/8805842|1017|416 |Opera/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;)               |\n",
      "+--------------+--------------+---------------------------+----+----+-------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.show(2, truncate=False)\n",
    "# Spark 2.3+: vertical=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe API: SQL Projections and Filters\n",
    "\n",
    "Projection is a subset of columns\n",
    "\n",
    "Filter is a asubset of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField(ip,StringType,true),\n",
       " StructField(timestamp,LongType,true),\n",
       " StructField(url,StringType,true),\n",
       " StructField(size,IntegerType,true),\n",
       " StructField(code,IntegerType,true),\n",
       " StructField(ua,StringType,true)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.schema.fields\n",
    "# Spark 2.3+:\n",
    "# >> log.schema.fieldNames()\n",
    "# ['ip', 'timestamp', 'url', 'size', 'code', 'ua']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ip: string, timestamp: bigint, url: string]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.select([\"ip\", \"timestamp\", \"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------+\n",
      "|            ip|     timestamp|                 url|\n",
      "+--------------+--------------+--------------------+\n",
      "|197.72.248.141|20140101020306|http://news.mail....|\n",
      "|222.131.187.37|20140101033837|http://news.mail....|\n",
      "|181.217.177.35|20140101052930|http://lenta.ru/4...|\n",
      "+--------------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select([\"ip\", \"timestamp\", \"url\"]).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+\n",
      "|            ip|code|\n",
      "+--------------+----+\n",
      "|197.72.248.141| 203|\n",
      "|222.131.187.37| 416|\n",
      "|181.217.177.35| 100|\n",
      "+--------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"ip\", \"code\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|            ip|     timestamp|                 url|size|code|                  ua|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|197.72.248.141|20140101020306|http://news.mail....|1412| 203|Safari/5.0 (compa...|\n",
      "|222.131.187.37|20140101033837|http://news.mail....|1017| 416|Opera/5.0 (compat...|\n",
      "|181.217.177.35|20140101052930|http://lenta.ru/4...|1976| 100|Safari/5.0 compat...|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"*\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|            ip|     timestamp|\n",
      "+--------------+--------------+\n",
      "|197.72.248.141|20140101020306|\n",
      "|222.131.187.37|20140101033837|\n",
      "|181.217.177.35|20140101052930|\n",
      "+--------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(log_df.ip, log_df.timestamp).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'ip'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aliasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+\n",
      "|            ip|response_code|\n",
      "+--------------+-------------+\n",
      "|197.72.248.141|          203|\n",
      "|222.131.187.37|          416|\n",
      "|181.217.177.35|          100|\n",
      "| 33.49.147.163|          422|\n",
      "| 75.208.40.166|          415|\n",
      "+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\n",
    "    log_df.ip,\n",
    "    log_df.code.alias(\"response_code\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+\n",
      "|            ip|response_code|\n",
      "+--------------+-------------+\n",
      "|197.72.248.141|          203|\n",
      "|222.131.187.37|          416|\n",
      "|181.217.177.35|          100|\n",
      "| 33.49.147.163|          422|\n",
      "| 75.208.40.166|          415|\n",
      "+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\n",
    "    \"ip\",\n",
    "    F.col(\"code\").alias(\"response_code\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good ol' Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+\n",
      "|            ip|code|\n",
      "+--------------+----+\n",
      "|197.72.248.141| 203|\n",
      "|222.131.187.37| 416|\n",
      "|181.217.177.35| 100|\n",
      "| 33.49.147.163| 422|\n",
      "| 75.208.40.166| 415|\n",
      "+--------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df[[\"ip\", \"code\"]].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+\n",
      "|            ip|response_code|\n",
      "+--------------+-------------+\n",
      "|197.72.248.141|          203|\n",
      "|222.131.187.37|          416|\n",
      "|181.217.177.35|          100|\n",
      "| 33.49.147.163|          422|\n",
      "| 75.208.40.166|          415|\n",
      "+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df[[log_df.ip, log_df.code.alias(\"response_code\")]].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|            ip|     timestamp|                 url|size|code|                  ua|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "| 75.208.40.166|20140104155237|http://news.rambl...|1307| 200|Opera/5.0 (compat...|\n",
      "| 33.49.147.163|20140106045941|http://news.rambl...| 671| 200|Firefox/5.0 (comp...|\n",
      "|110.91.102.196|20140108114835|http://news.mail....|1599| 200|Safari/5.0 (compa...|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.where(\"code == 200\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|            ip|     timestamp|                 url|size|code|                  ua|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "| 75.208.40.166|20140104155237|http://news.rambl...|1307| 200|Opera/5.0 (compat...|\n",
      "| 33.49.147.163|20140106045941|http://news.rambl...| 671| 200|Firefox/5.0 (comp...|\n",
      "|110.91.102.196|20140108114835|http://news.mail....|1599| 200|Safari/5.0 (compa...|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.where(log_df.code == 200).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+------------------------------+----+----+----------------------------------------------------------------------------------------------------------+\n",
      "|ip            |timestamp     |url                           |size|code|ua                                                                                                        |\n",
      "+--------------+--------------+------------------------------+----+----+----------------------------------------------------------------------------------------------------------+\n",
      "|75.208.40.166 |20140104155237|http://news.rambler.ru/9665982|1307|200 |Opera/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; chromeframe/12.0.742.112)            |\n",
      "|33.49.147.163 |20140106045941|http://news.rambler.ru/1817681|671 |200 |Firefox/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;)          |\n",
      "|110.91.102.196|20140108114835|http://news.mail.ru/1314430   |1599|200 |Safari/5.0 (compatible; MSIE 9.0; Windows NT 8.0; WOW64; Trident/5.0; .NET CLR 2.7.40781; .NET4.0E; en-SG)|\n",
      "+--------------+--------------+------------------------------+----+----+----------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.where(log_df.code == 200).show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+------------------------------+----+----+-------------------------------------------------------------------------------------------------------------+\n",
      "|ip             |timestamp     |url                           |size|code|ua                                                                                                           |\n",
      "+---------------+--------------+------------------------------+----+----+-------------------------------------------------------------------------------------------------------------+\n",
      "|135.124.143.193|20140106040300|http://news.rambler.ru/2362095|120 |200 |Safari/5.0 compatible; MSIE 9.0; Windows NT 7.0; Trident/5.0; .NET CLR 2.2.50767;)                           |\n",
      "|33.49.147.163  |20140109011807|http://news.rambler.ru/9760079|4   |200 |Safari/5.0 (compatible; MSIE 9.0; Windows NT 8.0; WOW64; Trident/5.0; .NET CLR 2.7.40781; .NET4.0E; en-SG)   |\n",
      "|197.72.248.141 |20140205145806|http://news.rambler.ru/1786267|1860|200 |Safari/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729;|\n",
      "+---------------+--------------+------------------------------+----+----+-------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.where(\"code = 200 AND url LIKE '%rambler%'\").show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|            ip|     timestamp|                 url|size|code|                  ua|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|197.72.248.141|20140101020306|http://news.mail....|1412| 203|Safari/5.0 (compa...|\n",
      "|222.131.187.37|20140101033837|http://news.mail....|1017| 416|Opera/5.0 (compat...|\n",
      "|181.217.177.35|20140101052930|http://lenta.ru/4...|1976| 100|Safari/5.0 compat...|\n",
      "| 33.49.147.163|20140101065321|http://news.rambl...|1155| 422|Safari/5.0 (compa...|\n",
      "| 75.208.40.166|20140101073934|http://lenta.ru/5...|1180| 415|Safari/5.0 (compa...|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.where(~log_df.code.isin([200, 400])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|            ip|     timestamp|                 url|size|code|                  ua|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|197.72.248.141|20140101034726|http://news.rambl...|2042| 428|Safari/5.0 (compa...|\n",
      "|56.167.169.126|20140101073452|http://news.rambl...|1286| 414|Opera/5.0 (compat...|\n",
      "|222.131.187.37|20140101132916|http://news.rambl...|1396| 105|Chrome/5.0 (Windo...|\n",
      "|197.72.248.141|20140101200021|http://news.rambl...| 160| 426|Opera/5.0 (compat...|\n",
      "| 75.208.40.166|20140101210547|http://news.rambl...|1571| 409|Chrome/5.0 (compa...|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.where(~log_df.code.isin([200, 400]) & (log_df.url.like(\"%rambler%\"))).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good ol' Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+--------------------+----+----+--------------------+\n",
      "|             ip|     timestamp|                 url|size|code|                  ua|\n",
      "+---------------+--------------+--------------------+----+----+--------------------+\n",
      "|135.124.143.193|20140106040300|http://news.rambl...| 120| 200|Safari/5.0 compat...|\n",
      "|  33.49.147.163|20140109011807|http://news.rambl...|   4| 200|Safari/5.0 (compa...|\n",
      "| 197.72.248.141|20140205145806|http://news.rambl...|1860| 200|Safari/5.0 (compa...|\n",
      "| 197.72.248.141|20140222074905|http://news.rambl...|1264| 200|Chrome/5.0 compat...|\n",
      "|  75.208.40.166|20140310132240|http://news.rambl...|1107| 200|Opera/5.0 (compat...|\n",
      "+---------------+--------------+--------------------+----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df[(log_df.code == 200) & (log_df.url.like(\"%rambler%\"))].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+\n",
      "|             ip|     timestamp|\n",
      "+---------------+--------------+\n",
      "|135.124.143.193|20140106040300|\n",
      "|  33.49.147.163|20140109011807|\n",
      "| 197.72.248.141|20140205145806|\n",
      "| 197.72.248.141|20140222074905|\n",
      "|  75.208.40.166|20140310132240|\n",
      "+---------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df[(log_df.code == 200) & (log_df.url.like(\"%rambler%\"))][[\"ip\", \"timestamp\"]].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"\n",
    "select ip, code from log_table \n",
    "where code = 200 and url LIKE '%rambler%'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.registerTempTable(\"log_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+\n",
      "|             ip|code|\n",
      "+---------------+----+\n",
      "|135.124.143.193| 200|\n",
      "|  33.49.147.163| 200|\n",
      "| 197.72.248.141| 200|\n",
      "+---------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql_query).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Three types:\n",
    "+ mapping (1:1, similar to Hive UDF)\n",
    "+ generating (1:(m)any, ~UDTF)\n",
    "+ aggregating (m:1, UDAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                  ua|length(ua)|\n",
      "+--------------------+----------+\n",
      "|Safari/5.0 (compa...|       109|\n",
      "|Opera/5.0 (compat...|        94|\n",
      "|Safari/5.0 compat...|        82|\n",
      "+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"ua\", F.length(\"ua\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                  ua|length|\n",
      "+--------------------+------+\n",
      "|Safari/5.0 (compa...|   109|\n",
      "|Opera/5.0 (compat...|    94|\n",
      "|Safari/5.0 compat...|    82|\n",
      "+--------------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"ua\", F.length(\"ua\").alias(\"length\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`?utf_medium=email`' given input columns: [ip, url, timestamp, ua, size, code];;\\n'Project [concat(url#89, '?utf_medium=email) AS concat(url, ?utf_medium=email)#973]\\n+- Repartition 4, true\\n   +- Relation[ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o154.select.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`?utf_medium=email`' given input columns: [ip, url, timestamp, ua, size, code];;\n'Project [concat(url#89, '?utf_medium=email) AS concat(url, ?utf_medium=email)#973]\n+- Repartition 4, true\n   +- Relation[ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:83)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:290)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:290)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:289)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4$$anonfun$apply$11.apply(TreeNode.scala:336)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:334)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:305)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:307)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:305)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:266)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:276)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$1.apply(QueryPlan.scala:280)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:280)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$6.apply(QueryPlan.scala:285)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:285)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:83)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:128)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:52)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:63)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:2845)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1131)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-03714b80b532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"?utf_medium=email\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \"\"\"\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`?utf_medium=email`' given input columns: [ip, url, timestamp, ua, size, code];;\\n'Project [concat(url#89, '?utf_medium=email) AS concat(url, ?utf_medium=email)#973]\\n+- Repartition 4, true\\n   +- Relation[ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] csv\\n\""
     ]
    }
   ],
   "source": [
    "log_df.select(F.concat(\"url\", \"?utf_medium=email\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|fixed_url                                   |\n",
      "+--------------------------------------------+\n",
      "|http://news.mail.ru/6344933?utf_medium=email|\n",
      "|http://news.mail.ru/8805842?utf_medium=email|\n",
      "|http://lenta.ru/4386687?utf_medium=email    |\n",
      "+--------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "log_df\n",
    "    .select(F.concat(\"url\", F.lit(\"?utf_medium=email\")).alias(\"fixed_url\"))\n",
    "    .show(3, truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explosions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|ua                                                                                                           |word_list                                                                                                                    |\n",
      "+-------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|Safari/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729;|[Safari/5.0, (compatible;, MSIE, 9.0;, Windows, NT, 6.1;, WOW64;, Trident/5.0;, .NET, CLR, 3.5.30729;, .NET, CLR, 3.0.30729;]|\n",
      "|Opera/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;)               |[Opera/5.0, (compatible;, MSIE, 9.0;, Windows, NT, 6.1;, Win64;, x64;, Trident/5.0;, .NET, CLR, 3.5.30729;)]                 |\n",
      "|Safari/5.0 compatible; MSIE 9.0; Windows NT 7.0; Trident/5.0; .NET CLR 2.2.50767;)                           |[Safari/5.0, compatible;, MSIE, 9.0;, Windows, NT, 7.0;, Trident/5.0;, .NET, CLR, 2.2.50767;)]                               |\n",
      "+-------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"ua\", F.split(\"ua\", \" \").alias(\"word_list\")).show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automagically, field selection works as it is in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                  ua|   browser|\n",
      "+--------------------+----------+\n",
      "|Safari/5.0 (compa...|Safari/5.0|\n",
      "|Opera/5.0 (compat...| Opera/5.0|\n",
      "|Safari/5.0 compat...|Safari/5.0|\n",
      "+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"ua\", F.split(\"ua\", \" \")[0].alias(\"browser\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|ua                                                                                                           |word_list                                                                                                                    |browser   |\n",
      "+-------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|Safari/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729;|[Safari/5.0, (compatible;, MSIE, 9.0;, Windows, NT, 6.1;, WOW64;, Trident/5.0;, .NET, CLR, 3.5.30729;, .NET, CLR, 3.0.30729;]|Safari/5.0|\n",
      "|Opera/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;)               |[Opera/5.0, (compatible;, MSIE, 9.0;, Windows, NT, 6.1;, Win64;, x64;, Trident/5.0;, .NET, CLR, 3.5.30729;)]                 |Opera/5.0 |\n",
      "|Safari/5.0 compatible; MSIE 9.0; Windows NT 7.0; Trident/5.0; .NET CLR 2.2.50767;)                           |[Safari/5.0, compatible;, MSIE, 9.0;, Windows, NT, 7.0;, Trident/5.0;, .NET, CLR, 2.2.50767;)]                               |Safari/5.0|\n",
      "+-------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    log_df\n",
    "    .select(\"ua\", F.split(\"ua\", \" \").alias(\"word_list\"))\n",
    "    .withColumn(\"browser\", F.col(\"word_list\")[0])\n",
    "    .show(3, False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|        word|count|\n",
      "+------------+-----+\n",
      "|     Windows|10092|\n",
      "|        9.0;|10092|\n",
      "|          NT|10092|\n",
      "|        MSIE|10092|\n",
      "|Trident/5.0;| 9121|\n",
      "|         CLR| 8119|\n",
      "|        .NET| 8119|\n",
      "|(compatible;| 6033|\n",
      "|      Win64;| 5085|\n",
      "|        x64;| 5085|\n",
      "+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    log_df\n",
    "    .select(\"ua\", F.split(\"ua\", \" \").alias(\"word_list\"))\n",
    "    .select(F.explode(\"word_list\").alias(\"word\"))\n",
    "    .groupBy(\"word\").count()\n",
    "    .orderBy(\"count\", ascending=False)\n",
    "    .show(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins and Repartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartitioned_log_df = log_df.repartition(2, \"ua\")\n",
    "log_df.rdd.getNumPartitions(), repartitioned_log_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ip: string, timestamp: bigint, url: string, size: int, code: int, ua: string]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specialized partitioner\n",
    "log_df.repartition(3, F.col(\"ua\") == \"MSIE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10092]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.repartition(2, F.col(\"ua\") == \"MSIE\").rdd.glom().map(lambda x: len(list(x))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5305, 4787]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.repartition(2, \"ua\").rdd.glom().map(lambda x: len(list(x))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.105.15.79\tKomi\r\n",
      "110.91.102.196\tChelyabinsk Oblast\r\n",
      "56.167.169.126\tSaint Petersburg\r\n",
      "75.208.40.166\tUlyanovsk Oblast\r\n",
      "168.255.93.197\tIrkutsk Oblast\r\n"
     ]
    }
   ],
   "source": [
    "! head -5 ipDataM.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_schema = types.StructType(fields=[\n",
    "    types.StructField(\"ip\", types.StringType()),\n",
    "    types.StructField(\"region\", types.StringType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ips_df = spark.read.csv(\"ipDataM.txt\", sep=\"\\t\", schema=ip_schema).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|            ip|            region|\n",
      "+--------------+------------------+\n",
      "|  49.105.15.79|              Komi|\n",
      "|110.91.102.196|Chelyabinsk Oblast|\n",
      "|56.167.169.126|  Saint Petersburg|\n",
      "+--------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ips_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_with_regions = log_df.join(ips_df, on=\"ip\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ip: string (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- size: integer (nullable = true)\n",
      " |-- code: integer (nullable = true)\n",
      " |-- ua: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_regions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------+----+----+--------------------+----------------+\n",
      "|            ip|     timestamp|                 url|size|code|                  ua|          region|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+----------------+\n",
      "|197.72.248.141|20140101020306|http://news.mail....|1412| 203|Safari/5.0 (compa...|Zabaykalsky Krai|\n",
      "|197.72.248.141|20140101020306|http://news.mail....|1412| 203|Safari/5.0 (compa...|  Stavropol Krai|\n",
      "|197.72.248.141|20140101020306|http://news.mail....|1412| 203|Safari/5.0 (compa...|        Chechnya|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_regions.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_with_regions.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Join UsingJoin(Inner,Buffer(ip))\n",
      ":- Repartition 4, true\n",
      ":  +- Relation[ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] csv\n",
      "+- Relation[ip#1317,region#1318] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "ip: string, timestamp: bigint, url: string, size: int, code: int, ua: string, region: string\n",
      "Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318]\n",
      "+- Join Inner, (ip#87 = ip#1317)\n",
      "   :- Repartition 4, true\n",
      "   :  +- Relation[ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] csv\n",
      "   +- Relation[ip#1317,region#1318] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318]\n",
      "+- Join Inner, (ip#87 = ip#1317)\n",
      "   :- Repartition 4, true\n",
      "   :  +- Filter isnotnull(ip#87)\n",
      "   :     +- InMemoryRelation [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :           +- *FileScan csv [ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/logsM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,timestamp:bigint,url:string,size:int,code:int,ua:string>\n",
      "   +- Filter isnotnull(ip#1317)\n",
      "      +- InMemoryRelation [ip#1317, region#1318], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- *FileScan csv [ip#1317,region#1318] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/ipDataM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,region:string>\n",
      "\n",
      "== Physical Plan ==\n",
      "*Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318]\n",
      "+- *BroadcastHashJoin [ip#87], [ip#1317], Inner, BuildRight\n",
      "   :- Exchange RoundRobinPartitioning(4)\n",
      "   :  +- *Filter isnotnull(ip#87)\n",
      "   :     +- InMemoryTableScan [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92], [isnotnull(ip#87)]\n",
      "   :           +- InMemoryRelation [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :                 +- *FileScan csv [ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/logsM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,timestamp:bigint,url:string,size:int,code:int,ua:string>\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]))\n",
      "      +- *Filter isnotnull(ip#1317)\n",
      "         +- InMemoryTableScan [ip#1317, region#1318], [isnotnull(ip#1317)]\n",
      "               +- InMemoryRelation [ip#1317, region#1318], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                     +- *FileScan csv [ip#1317,region#1318] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/ipDataM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,region:string>\n"
     ]
    }
   ],
   "source": [
    "log_with_regions.explain(extended=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compare with what we would have for big tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SET spark.sql.autoBroadcastJoinThreshold = 100500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_with_regions = log_df.join(ips_df, on=\"ip\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_with_regions.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.shuffle.partitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_with_regions = log_with_regions.repartition(4).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Repartition 4, true\n",
      "+- Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318]\n",
      "   +- Join Inner, (ip#87 = ip#1317)\n",
      "      :- Repartition 4, true\n",
      "      :  +- Relation[ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] csv\n",
      "      +- Relation[ip#1317,region#1318] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "ip: string, timestamp: bigint, url: string, size: int, code: int, ua: string, region: string\n",
      "Repartition 4, true\n",
      "+- Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318]\n",
      "   +- Join Inner, (ip#87 = ip#1317)\n",
      "      :- Repartition 4, true\n",
      "      :  +- Relation[ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] csv\n",
      "      +- Relation[ip#1317,region#1318] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "InMemoryRelation [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   +- Exchange RoundRobinPartitioning(4)\n",
      "      +- *Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318]\n",
      "         +- *SortMergeJoin [ip#87], [ip#1317], Inner\n",
      "            :- *Sort [ip#87 ASC NULLS FIRST], false, 0\n",
      "            :  +- Exchange hashpartitioning(ip#87, 200)\n",
      "            :     +- Exchange RoundRobinPartitioning(4)\n",
      "            :        +- *Filter isnotnull(ip#87)\n",
      "            :           +- InMemoryTableScan [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92], [isnotnull(ip#87)]\n",
      "            :                 +- InMemoryRelation [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            :                       +- *FileScan csv [ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/logsM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,timestamp:bigint,url:string,size:int,code:int,ua:string>\n",
      "            +- *Sort [ip#1317 ASC NULLS FIRST], false, 0\n",
      "               +- Exchange hashpartitioning(ip#1317, 200)\n",
      "                  +- *Filter isnotnull(ip#1317)\n",
      "                     +- InMemoryTableScan [ip#1317, region#1318], [isnotnull(ip#1317)]\n",
      "                           +- InMemoryRelation [ip#1317, region#1318], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                                 +- *FileScan csv [ip#1317,region#1318] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/ipDataM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,region:string>\n",
      "\n",
      "== Physical Plan ==\n",
      "InMemoryTableScan [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318]\n",
      "   +- InMemoryRelation [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         +- Exchange RoundRobinPartitioning(4)\n",
      "            +- *Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318]\n",
      "               +- *SortMergeJoin [ip#87], [ip#1317], Inner\n",
      "                  :- *Sort [ip#87 ASC NULLS FIRST], false, 0\n",
      "                  :  +- Exchange hashpartitioning(ip#87, 200)\n",
      "                  :     +- Exchange RoundRobinPartitioning(4)\n",
      "                  :        +- *Filter isnotnull(ip#87)\n",
      "                  :           +- InMemoryTableScan [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92], [isnotnull(ip#87)]\n",
      "                  :                 +- InMemoryRelation [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                  :                       +- *FileScan csv [ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/logsM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,timestamp:bigint,url:string,size:int,code:int,ua:string>\n",
      "                  +- *Sort [ip#1317 ASC NULLS FIRST], false, 0\n",
      "                     +- Exchange hashpartitioning(ip#1317, 200)\n",
      "                        +- *Filter isnotnull(ip#1317)\n",
      "                           +- InMemoryTableScan [ip#1317, region#1318], [isnotnull(ip#1317)]\n",
      "                                 +- InMemoryRelation [ip#1317, region#1318], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                                       +- *FileScan csv [ip#1317,region#1318] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/ipDataM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,region:string>\n"
     ]
    }
   ],
   "source": [
    "log_with_regions.explain(extended=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query planner uses SortMergeJoin by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One more thing: broadcast hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318]\n",
      "+- *BroadcastHashJoin [ip#87], [ip#1317], Inner, BuildRight\n",
      "   :- Exchange RoundRobinPartitioning(4)\n",
      "   :  +- *Filter isnotnull(ip#87)\n",
      "   :     +- InMemoryTableScan [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92], [isnotnull(ip#87)]\n",
      "   :           +- InMemoryRelation [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :                 +- *FileScan csv [ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/logsM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,timestamp:bigint,url:string,size:int,code:int,ua:string>\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]))\n",
      "      +- *Filter isnotnull(ip#1317)\n",
      "         +- InMemoryTableScan [ip#1317, region#1318], [isnotnull(ip#1317)]\n",
      "               +- InMemoryRelation [ip#1317, region#1318], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                     +- *FileScan csv [ip#1317,region#1318] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/ipDataM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,region:string>\n"
     ]
    }
   ],
   "source": [
    "log_with_regions = log_df.join(F.broadcast(ips_df), on=\"ip\", how=\"inner\")\n",
    "log_with_regions.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark 2.3+: Hint method for Dataframes\n",
    "# log_with_regions = log_df.join(ips_df.hint(\"broadcast\"), on=\"ip\", how=\"inner\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Pipeline:\n",
    "```python\n",
    "df.groupBy(*cols)\\\n",
    "  .agg(*expressions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|           region| count|\n",
      "+-----------------+------+\n",
      "|    Kaluga Oblast|111297|\n",
      "|    Ryazan Oblast| 80716|\n",
      "|  Smolensk Oblast| 99735|\n",
      "|Sverdlovsk Oblast| 87004|\n",
      "|          Mari El| 98414|\n",
      "|   Irkutsk Oblast|113353|\n",
      "|   Vologda Oblast|122363|\n",
      "|    Kurgan Oblast| 86787|\n",
      "|   Krasnodar Krai|102161|\n",
      "|    Rostov Oblast| 95547|\n",
      "+-----------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "log_with_regions\n",
    "    .groupBy(\"region\")\n",
    "    .agg(F.count(\"ip\").alias(\"count\"))\n",
    "    .show(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|           region|count|\n",
      "+-----------------+-----+\n",
      "|    Kaluga Oblast|   15|\n",
      "|    Ryazan Oblast|   14|\n",
      "|  Smolensk Oblast|   14|\n",
      "|Sverdlovsk Oblast|   15|\n",
      "|          Mari El|   15|\n",
      "|   Vologda Oblast|   14|\n",
      "|   Irkutsk Oblast|   15|\n",
      "|    Kurgan Oblast|   14|\n",
      "|   Krasnodar Krai|   17|\n",
      "|    Rostov Oblast|   15|\n",
      "+-----------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "log_with_regions\n",
    "    .groupBy(\"region\")\n",
    "    .agg(F.countDistinct(\"ip\").alias(\"count\"))\n",
    "    .show(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+\n",
      "|           region|row_count|\n",
      "+-----------------+---------+\n",
      "|    Kaluga Oblast|   111297|\n",
      "|    Ryazan Oblast|    80716|\n",
      "|  Smolensk Oblast|    99735|\n",
      "|Sverdlovsk Oblast|    87004|\n",
      "|          Mari El|    98414|\n",
      "|   Irkutsk Oblast|   113353|\n",
      "|   Vologda Oblast|   122363|\n",
      "|    Kurgan Oblast|    86787|\n",
      "|   Krasnodar Krai|   102161|\n",
      "|    Rostov Oblast|    95547|\n",
      "+-----------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "log_with_regions\n",
    "    .groupBy(\"region\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"row_count\")\n",
    "    .show(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|            region|row_count|\n",
      "+------------------+---------+\n",
      "|  Ulyanovsk Oblast|   204275|\n",
      "|            Jewish|   134523|\n",
      "|  Saint Petersburg|   129362|\n",
      "|Arkhangelsk Oblast|   124937|\n",
      "|    Vologda Oblast|   122363|\n",
      "|   Novgorod Oblast|   122306|\n",
      "|     Moscow Oblast|   120336|\n",
      "|  Krasnoyarsk Krai|   119285|\n",
      "|              Komi|   117659|\n",
      "|          Kalmykia|   117172|\n",
      "+------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "log_with_regions\n",
    "    .groupBy(\"region\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"row_count\")\n",
    "    .orderBy(\"row_count\", ascending=False)\n",
    "    .show(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|url_length|row_count|\n",
      "+----------+---------+\n",
      "|        23|  1676363|\n",
      "|        27|  1644000|\n",
      "|        25|  1639043|\n",
      "|        29|  1638174|\n",
      "|        30|  1617023|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "log_with_regions\n",
    "    .groupBy(F.length(\"url\").alias(\"url_length\"))\n",
    "    .agg(F.count(\"*\").alias(\"row_count\"))\n",
    "    .orderBy(\"row_count\", ascending=False)\n",
    "    .show(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_stat = (\n",
    "    log_with_regions\n",
    "    .groupBy(F.length(\"url\").alias(\"url_length\"))\n",
    "    .agg(F.count(\"*\").alias(\"row_count\"))\n",
    "    .orderBy(\"row_count\", ascending=False)\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_length</th>\n",
       "      <th>row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>1676363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>1644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>1639043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>1638174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>1617023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_length  row_count\n",
       "0          23    1676363\n",
       "1          27    1644000\n",
       "2          25    1639043\n",
       "3          29    1638174\n",
       "4          30    1617023"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4c02aa5be0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAENCAYAAADKcIhSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHoFJREFUeJzt3XuYVfV97/H3pww36wWF0RjGk+EoXhBvMBHUxJrQKBoj\nnlQbPK1SS8KJ0Vyamxj7hMTUPFrb2tASUwwUTK3IIYlyEpRyFE9ivcCIKCJRxktlxMsoaIgGFf2e\nP9ZvnM249+xh1swsxvm8nmeeWeu7fmv9fns9wId12WspIjAzM8vjD4oegJmZ9X0OEzMzy81hYmZm\nuTlMzMwsN4eJmZnl5jAxM7PcHCZmZpabw8TMzHJzmJiZWW41RQ+gt4wYMSLq6+uLHoaZWZ/ywAMP\nvBQRtdXa9Zswqa+vp7GxsehhmJn1KZL+qzPtfJrLzMxyc5iYmVluDhMzM8vNYWJmZrk5TMzMLDeH\niZmZ5eYwMTOz3BwmZmaWW7/50mJ3qJ/5y6KHwNNXfbLoIZiZvYePTMzMLDeHiZmZ5eYwMTOz3HzN\nxLrE14/MrJTDxCwnB2sb74v+q+ppLknzJb0o6ZF29S9KekzSekl/W1K/TFJTWnZaSX1yqjVJmllS\nHyXpfkkbJd0saVCqD07zTWl5fbU+zMysGJ05MlkA/DNwQ2tB0seAKcDREfGGpP1TfQwwFTgS+CDw\nfyUdmlabA3wCaAZWS1oaEY8CVwPXRsQiST8CpgPXpd9bI+IQSVNTu89U6iMi3s6zI8zMulN/O0qr\nemQSEb8CtrQrXwRcFRFvpDYvpvoUYFFEvBERTwFNwPHppykinoyIN4FFwBRJAj4OLEnrLwTOLtnW\nwjS9BJiU2lfqw8zMCtLVu7kOBT6aTj/9P0kfTvWRwKaSds2pVqk+HHglIna0q++0rbT81dS+0rbe\nQ9IMSY2SGltaWrr0Qc3MrLquhkkNsC8wEfgGsDgdNahM2+hCnS6us3MxYm5ENEREQ21t1VcYm5lZ\nF3U1TJqBn0VmFfAOMCLVDyppVwds7qD+EjBMUk27OqXrpOX7kJ1uq7QtMzMrSFfD5Bayax2kC+yD\nyIJhKTA13Yk1ChgNrAJWA6PTnVuDyC6gL42IAFYC56TtTgNuTdNL0zxp+Z2pfaU+zMysIFXv5pJ0\nE3AKMEJSMzALmA/MT7cLvwlMS//Qr5e0GHgU2AFc3HqXlaRLgOXAAGB+RKxPXVwKLJL0N8CDwLxU\nnwf8RFIT2RHJVICIqNiHmZkVo2qYRMR5FRb9eYX2VwJXlqkvA5aVqT9JmbuxImI7cO6u9GFmZsXw\ns7nMzCw3h4mZmeXmMDEzs9wcJmZmlpvDxMzMcnOYmJlZbg4TMzPLzWFiZma5OUzMzCw3h4mZmeXm\nMDEzs9wcJmZmlpvDxMzMcnOYmJlZbg4TMzPLzWFiZma5VQ0TSfMlvZjeqth+2dclhaQRaV6SZktq\nkvSwpHElbadJ2ph+ppXUx0tal9aZLUmpvp+kFan9Ckn7VuvDzMyK0ZkjkwXA5PZFSQcBnwCeKSmf\nTvZO9tHADOC61HY/stf9TiB7q+Ks1nBIbWaUrNfa10zgjogYDdyR5iv2YWZmxakaJhHxK7J3sLd3\nLfBNIEpqU4AbInMfMEzSgcBpwIqI2BIRW4EVwOS0bO+IuDe9Q/4G4OySbS1M0wvb1cv1YWZmBenS\nNRNJZwHPRsRD7RaNBDaVzDenWkf15jJ1gAMi4jmA9Hv/Kn2UG+cMSY2SGltaWjr56czMbFftcphI\n2gO4HPh2ucVlatGFeodD6Ow6ETE3IhoioqG2trbKZs3MrKu6cmRyMDAKeEjS00AdsEbSB8iOEg4q\naVsHbK5SrytTB3ih9fRV+v1iqlfalpmZFWSXwyQi1kXE/hFRHxH1ZP+4j4uI54GlwAXpjquJwKvp\nFNVy4FRJ+6YL76cCy9OybZImpru4LgBuTV0tBVrv+prWrl6uDzMzK0hNtQaSbgJOAUZIagZmRcS8\nCs2XAWcATcDrwIUAEbFF0veA1andFRHRelH/IrI7xoYCt6UfgKuAxZKmk90xdm5HfZiZWXGqhklE\nnFdleX3JdAAXV2g3H5hfpt4IjC1TfxmYVKZesQ8zMyuGvwFvZma5OUzMzCw3h4mZmeXmMDEzs9wc\nJmZmlpvDxMzMcnOYmJlZbg4TMzPLzWFiZma5OUzMzCw3h4mZmeXmMDEzs9wcJmZmlpvDxMzMcnOY\nmJlZbg4TMzPLrWqYSJov6UVJj5TUrpH0G0kPS/q5pGElyy6T1CTpMUmnldQnp1qTpJkl9VGS7pe0\nUdLNkgal+uA035SW11frw8zMitGZI5MFwOR2tRXA2Ig4GngcuAxA0hhgKnBkWueHkgZIGgDMAU4H\nxgDnpbYAVwPXRsRoYCswPdWnA1sj4hDg2tSuYh+7+LnNzKwbVQ2TiPgVsKVd7T8iYkeavQ+oS9NT\ngEUR8UZEPEX2nvbj009TRDwZEW8Ci4ApkgR8HFiS1l8InF2yrYVpegkwKbWv1IeZmRWkO66Z/CVw\nW5oeCWwqWdacapXqw4FXSoKptb7TttLyV1P7Stt6D0kzJDVKamxpaenShzMzs+pyhYmky4EdwI2t\npTLNogv1rmzrvcWIuRHREBENtbW15ZqYmVk3qOnqipKmAWcCkyKi9R/zZuCgkmZ1wOY0Xa7+EjBM\nUk06+iht37qtZkk1wD5kp9s66sPMzArQpSMTSZOBS4GzIuL1kkVLganpTqxRwGhgFbAaGJ3u3BpE\ndgF9aQqhlcA5af1pwK0l25qWps8B7kztK/VhZmYFqXpkIukm4BRghKRmYBbZ3VuDgRXZNXHui4jP\nR8R6SYuBR8lOf10cEW+n7VwCLAcGAPMjYn3q4lJgkaS/AR4E5qX6POAnkprIjkimAnTUh5mZFaNq\nmETEeWXK88rUWttfCVxZpr4MWFam/iRl7saKiO3AubvSh5mZFcPfgDczs9wcJmZmlpvDxMzMcnOY\nmJlZbg4TMzPLzWFiZma5OUzMzCw3h4mZmeXmMDEzs9wcJmZmlpvDxMzMcnOYmJlZbg4TMzPLzWFi\nZma5OUzMzCw3h4mZmeVWNUwkzZf0oqRHSmr7SVohaWP6vW+qS9JsSU2SHpY0rmSdaan9xvT++Nb6\neEnr0jqzlV7d2JU+zMysGJ05MlkATG5XmwncERGjgTvSPMDpZO9kHw3MAK6DLBjIXvc7geytirNa\nwyG1mVGy3uSu9GFmZsWpGiYR8Suyd7CXmgIsTNMLgbNL6jdE5j5gmKQDgdOAFRGxJSK2AiuAyWnZ\n3hFxb0QEcEO7be1KH2ZmVpCuXjM5ICKeA0i/90/1kcCmknbNqdZRvblMvSt9vIekGZIaJTW2tLTs\n0gc0M7PO6+4L8CpTiy7Uu9LHe4sRcyOiISIaamtrq2zWzMy6qqth8kLrqaX0+8VUbwYOKmlXB2yu\nUq8rU+9KH2ZmVpCuhslSoPWOrGnArSX1C9IdVxOBV9MpquXAqZL2TRfeTwWWp2XbJE1Md3Fd0G5b\nu9KHmZkVpKZaA0k3AacAIyQ1k92VdRWwWNJ04Bng3NR8GXAG0AS8DlwIEBFbJH0PWJ3aXRERrRf1\nLyK7Y2wocFv6YVf7MDOz4lQNk4g4r8KiSWXaBnBxhe3MB+aXqTcCY8vUX97VPszMrBj+BryZmeXm\nMDEzs9wcJmZmlpvDxMzMcnOYmJlZbg4TMzPLzWFiZma5OUzMzCw3h4mZmeXmMDEzs9wcJmZmlpvD\nxMzMcnOYmJlZbg4TMzPLzWFiZma55QoTSX8lab2kRyTdJGmIpFGS7pe0UdLNkgaltoPTfFNaXl+y\nnctS/TFJp5XUJ6dak6SZJfWyfZiZWTG6HCaSRgJfAhoiYiwwAJgKXA1cGxGjga3A9LTKdGBrRBwC\nXJvaIWlMWu9IYDLwQ0kDJA0A5gCnA2OA81JbOujDzMwKkPc0Vw0wVFINsAfwHPBxYElavhA4O01P\nSfOk5ZPSe9+nAIsi4o2IeIrsdbzHp5+miHgyIt4EFgFT0jqV+jAzswJ0OUwi4lng78jez/4c8Crw\nAPBKROxIzZqBkWl6JLAprbsjtR9eWm+3TqX68A762ImkGZIaJTW2tLR09aOamVkVeU5z7Ut2VDEK\n+CDwh2SnpNqL1lUqLOuu+nuLEXMjoiEiGmpra8s1MTOzbpDnNNcfA09FREtEvAX8DDgRGJZOewHU\nAZvTdDNwEEBavg+wpbTebp1K9Zc66MPMzAqQJ0yeASZK2iNdx5gEPAqsBM5JbaYBt6bppWmetPzO\niIhUn5ru9hoFjAZWAauB0enOrUFkF+mXpnUq9WFmZgXIc83kfrKL4GuAdWlbc4FLga9KaiK7vjEv\nrTIPGJ7qXwVmpu2sBxaTBdHtwMUR8Xa6JnIJsBzYACxObemgDzMzK0BN9SaVRcQsYFa78pNkd2K1\nb7sdOLfCdq4ErixTXwYsK1Mv24eZmRXD34A3M7PcHCZmZpabw8TMzHJzmJiZWW4OEzMzy81hYmZm\nuTlMzMwsN4eJmZnl5jAxM7PcHCZmZpabw8TMzHJzmJiZWW4OEzMzy81hYmZmuTlMzMwsN4eJmZnl\nlitMJA2TtETSbyRtkHSCpP0krZC0Mf3eN7WVpNmSmiQ9LGlcyXampfYbJU0rqY+XtC6tMzu9HphK\nfZiZWTHyHpn8ALg9Ig4HjiF7ve5M4I6IGA3ckeYBTid7v/toYAZwHWTBQPa2xglkb0+cVRIO16W2\nretNTvVKfZiZWQG6HCaS9gZOJr1/PSLejIhXgCnAwtRsIXB2mp4C3BCZ+4Bhkg4ETgNWRMSWiNgK\nrAAmp2V7R8S9ERHADe22Va4PMzMrQJ4jk/8OtAD/KulBST+W9IfAARHxHED6vX9qPxLYVLJ+c6p1\nVG8uU6eDPnYiaYakRkmNLS0tXf+kZmbWoTxhUgOMA66LiOOA1+j4dJPK1KIL9U6LiLkR0RARDbW1\ntbuyqpmZ7YI8YdIMNEfE/Wl+CVm4vJBOUZF+v1jS/qCS9euAzVXqdWXqdNCHmZkVoMthEhHPA5sk\nHZZKk4BHgaVA6x1Z04Bb0/RS4IJ0V9dE4NV0imo5cKqkfdOF91OB5WnZNkkT011cF7TbVrk+zMys\nADU51/8icKOkQcCTwIVkAbVY0nTgGeDc1HYZcAbQBLye2hIRWyR9D1id2l0REVvS9EXAAmAocFv6\nAbiqQh9mZlaAXGESEWuBhjKLJpVpG8DFFbYzH5hfpt4IjC1Tf7lcH2ZmVgx/A97MzHJzmJiZWW4O\nEzMzy81hYmZmuTlMzMwsN4eJmZnl5jAxM7PcHCZmZpabw8TMzHJzmJiZWW4OEzMzy81hYmZmuTlM\nzMwsN4eJmZnl5jAxM7PcHCZmZpZb7jCRNEDSg5J+keZHSbpf0kZJN6e3MCJpcJpvSsvrS7ZxWao/\nJum0kvrkVGuSNLOkXrYPMzMrRnccmXwZ2FAyfzVwbUSMBrYC01N9OrA1Ig4Brk3tkDQGmAocCUwG\nfpgCagAwBzgdGAOcl9p21IeZmRUgV5hIqgM+Cfw4zQv4OLAkNVkInJ2mp6R50vJJqf0UYFFEvBER\nT5G9I/749NMUEU9GxJvAImBKlT7MzKwAeY9M/hH4JvBOmh8OvBIRO9J8MzAyTY8ENgGk5a+m9u/W\n261Tqd5RHzuRNENSo6TGlpaWrn5GMzOrosthIulM4MWIeKC0XKZpVFnWXfX3FiPmRkRDRDTU1taW\na2JmZt2gJse6JwFnSToDGALsTXakMkxSTTpyqAM2p/bNwEFAs6QaYB9gS0m9Vek65eovddCHmZkV\noMtHJhFxWUTURUQ92QX0OyPiz4CVwDmp2TTg1jS9NM2Tlt8ZEZHqU9PdXqOA0cAqYDUwOt25NSj1\nsTStU6kPMzMrQE98z+RS4KuSmsiub8xL9XnA8FT/KjATICLWA4uBR4HbgYsj4u101HEJsJzsbrHF\nqW1HfZiZWQHynOZ6V0TcBdyVpp8kuxOrfZvtwLkV1r8SuLJMfRmwrEy9bB9mZlYMfwPezMxyc5iY\nmVluDhMzM8vNYWJmZrk5TMzMLDeHiZmZ5eYwMTOz3BwmZmaWm8PEzMxyc5iYmVluDhMzM8vNYWJm\nZrk5TMzMLDeHiZmZ5eYwMTOz3PK8A/4gSSslbZC0XtKXU30/SSskbUy/9011SZotqUnSw5LGlWxr\nWmq/UdK0kvp4SevSOrMlqaM+zMysGHmOTHYAX4uII4CJwMWSxpC9QfGOiBgN3JHmAU4neyXvaGAG\ncB1kwQDMAiaQvfBqVkk4XJfatq43OdUr9WFmZgXI8w745yJiTZreRvZq3ZHAFGBharYQODtNTwFu\niMx9wDBJBwKnASsiYktEbAVWAJPTsr0j4t703vcb2m2rXB9mZlaAbrlmIqkeOA64HzggIp6DLHCA\n/VOzkcCmktWaU62jenOZOh300X5cMyQ1SmpsaWnp6sczM7Mqcr8DXtKewE+Br0TEb9NljbJNy9Si\nC/VOi4i5wFyAhoaGXVrX+ra33nqL5uZmtm/f3uN9XX/WgT3eRzUbNmzolX6GDBlCXV0dAwcO7JX+\nrO/IFSaSBpIFyY0R8bNUfkHSgRHxXDpV9WKqNwMHlaxeB2xO9VPa1e9K9boy7TvqwwyA5uZm9tpr\nL+rr6+ngPzjd4q3mV3p0+51xRN2wHu8jInj55Zdpbm5m1KhRPd6f9S157uYSMA/YEBH/ULJoKdB6\nR9Y04NaS+gXprq6JwKvpFNVy4FRJ+6YL76cCy9OybZImpr4uaLetcn2YAbB9+3aGDx/e40HSn0hi\n+PDhvXK0Z31PniOTk4DzgXWS1qbat4CrgMWSpgPPAOemZcuAM4Am4HXgQoCI2CLpe8Dq1O6KiNiS\npi8CFgBDgdvSDx30YfYuB0n38z61SrocJhFxN+WvawBMKtM+gIsrbGs+ML9MvREYW6b+crk+zMys\nGLkvwJv1BfUzf9mt23v6qk926/Z2N7fccguHHnooY8aMKXoo1kf4cSpmvSAieOedd4oeRqfdcsst\nPProo0UPw/oQh4lZD3l20zOc/bEJXPmtr/GZ0/+IX/z0Zv7kj0/k05NO4NrvzwJg+f/5Odd893IA\nbpz3I8446VgANj39FNM+Pbnith9Zu4YLzj6Vc0/9CP/zzEls27aN7du3c+GFF3LUUUdx3HHHsXLl\nSgAWLFjAJZdc8u66Z555JnfddRcAe+65J5dffjnHHHMMEydO5IUXXuCee+5h6dKlfOMb3+DYY4/l\niSee6IndY+8zDhOzHvT0Exv51DlT+ecFNzPn767k+puXsnj5r1n/0IPcefsvGT/hRB5cdS8Aa1bd\ny7Bh+/HCc5t5cPV9jDv+hLLbfOvNN/nmxX/JN79zFf/7P+5m7k0/Z+jQocyZMweAdevWcdNNNzFt\n2rSqd1699tprTJw4kYceeoiTTz6Z66+/nhNPPJGzzjqLa665hrVr13LwwQd3706x9yWHiVkPOrDu\nII4e92HWP/QgDSd8hP2Gj6CmpoYz/se5PHD/PYzY/wBef/01XvvdNp7f/Cynn30Oa+6/hzWr7q0Y\nJk8/sZHa/Q9g7LHZs1L33GtvampquPvuuzn//PMBOPzww/nQhz7E448/3uH4Bg0axJlnngnA+PHj\nefrpp7vvw1u/4jAx60FDh+4BZNdMKjl63Ie5ZfG/U3/wIYw7/gTWrLqXh9as5tiGCWXbBwFlbtGt\n1EdNTc1O12tKj1YGDhz47u2+AwYMYMeOHdU/lFkZDhOzXnDUceN54L7/ZOuWl3n77be5/daf0jDx\nJADGTziRG/7lnxg/4UQOH3s0q++9m0GDBrHX3vuU3daogw+l5YXneWTtGgBe+902duzYwcknn8yN\nN94IwOOPP84zzzzDYYcdRn19PWvXruWdd95h06ZNrFq1qup499prL7Zt29ZNn976A98abP1C0bfy\n1h7wAb506bf57J9+iojgox//BB877QwAxh1/As9vfpZxE05kwIABHHDgSEYdMrritgYOGsTfzpnP\nVd++lDe2/57BQ4Zyz69W8oUvfIHPf/7zHHXUUdTU1LBgwQIGDx7MSSedxKhRozjqqKMYO3Ys48aN\nq7jtVlOnTuVzn/scs2fPZsmSJb5uYlWpo8Pv95OGhoZobGzMtY3u/q5CVxT9j2Kr3X1fbNiwgSOO\nOKJXxvHwbvBsrqN74dlcrTrat7v7n4ve9H7ZF5IeiIiGau18msvMzHLzaS6z3dhXPvvnbN70XzvV\nvnzZdzjpFD9NyHYvDhOz3dg//vjfih6CWaf4NJe9b/WX64G9yfvUKnGY2PvSkCFDePnll/2PXzdq\nfTnWkCFDih6K7YZ8msvel+rq6mhubqalpaXH+3ph6+97vI9qNmwb2iv9tL6216w9h4m9Lw0cOLDX\nXi17+vvkFlCzPPr0aS5JkyU9JqlJ0syix2Nm1l/12TCRNACYA5wOjAHOk+Q3+ZiZFaDPhglwPNAU\nEU9GxJvAImBKwWMyM+uX+uzjVCSdA0yOiM+m+fOBCRFxSUmbGcCMNHsY8FivD/S9RgAvFT2I3YT3\nRRvvizbeF212h33xoYiordaoL1+Af+8zuGGnZIyIucDc3hlO50hq7MxzbvoD74s23hdtvC/a9KV9\n0ZdPczUDB5XM1wGbCxqLmVm/1pfDZDUwWtIoSYOAqcDSgsdkZtYv9dnTXBGxQ9IlwHJgADA/ItYX\nPKzO2K1OuxXM+6KN90Ub74s2fWZf9NkL8GZmtvvoy6e5zMxsN+EwMTOz3BwmZmaWm8PEzMxyc5iY\nmVluDpMeIukDkq6TNEfScEnfkbRO0mJJBxY9vt4kaY2kv5Z0cNFjKZqkySXT+0iaJ+lhSf8u6YAi\nx9bbJO0p6QpJ6yW9KqlF0n2S/qLosfU2STWS/pek29Ofh4ck3Sbp85IGFj2+znCY9JwFwKPAJmAl\n8Hvgk8CvgR8VN6xC7AsMA1ZKWiXpryR9sOhBFeT7JdN/DzwHfIrsS7j/UsiIinMj8CRwGvBdYDZw\nPvAxSd/vaMX3oZ8AxwLfAc4g+7fiu8AxwL8VN6zO8/dMeoikByPiuDT9TET8t5JlayPi2OJG17sk\nrYmIcWn6o8B5wKeBDcBN6Rlq/UK7fbHTn4N++OfioYg4pmR+dUR8WNIfAI9GxOEFDq9XSXosIg6r\nsOzxiDi0t8e0q3xk0nNK9+0N7ZYN6M2B7E4i4tcR8QVgJHA1cELBQ+pt+0v6qqSvAXtLKn1gaX/7\n+/iapI8ASPoUsAUgIt6h/INc38+2Sjo3BSkAkv5A0meArQWOq9P67ONU+oBbJe0ZEb+LiL9uLUo6\nhN3jUfi96fH2hYh4G7g9/fQn1wN7pemFZI8Yb5H0AWBtYaMqxkXA9ZIOBR4BpgNIqiV78V1/MpXs\nP1dzJL2SasPITpFPLWxUu8CnuXqQpMPJ/gd+f0T8rqQ+OSL61T+i3hdtvC/aSDqCbF/c532hCWSv\n0XgCOAKYSHa6b1mhA+uk/nZY3WskfRG4Ffgi8Iik0rdA9quLi94Xbbwv2kj6EvBz4BK8L2YBPwB+\nCHyd7OL7HsBMSZcXObbO8mmunjMDGB8Rv5NUDyyRVB8RP6D/nQ/2vmjjfdHmc0CD9wUA55DdzTUY\neB6oi4jfSroGuB+4ssjBdYbDpOcMaD1sj4inJZ1C9pflQ/S/vyjeF228L9p4X7TZka4jvi7piYj4\nLUBE/F7SOwWPrVN8mqvnPC/p3ds801+aM8kuuB5V2KiK4X3RxvuijfdFmzcl7ZGmx7cWJe0D9Ikw\n8QX4HiKpjux/G8+XWXZSRPxnAcMqhPdFG++LNt4XbSQNjog3ytRHAAdGxLoChrVLHCZmZpabT3OZ\nmVluDhMzM8vNYWJmZrk5TMy6SXrNwNc7WL5A0jk90O+3SqbrJT3S3X2YVeMwMesGkor8zta3qjcx\n61n+0qJZFenb2b+IiLFp/uvAnsApwD3AScDSXdzmeOAf0nZeAv4iIp6TdBfZN54/Rvagv+kR8ev0\nHYQFwOFkj+6vBy4m++b0UElrgfXA5cAASdcDJwLPAlMi4vdd+vBmneQjE7N8hkXEH0XE33d2hfTm\nvH8CzomI8cB8dn5cRk1EHA98BZiVal8AtkbE0cD3SF9si4iZwO8j4tiI+LPUdjQwJyKOBF4B/qTr\nH8+sc3xkYpbPzV1Y5zBgLLAivc5kANkbF1v9LP1+gOwIBOAjZA8CJCIekfRwB9t/KiJaH2dfug2z\nHuMwMatuBzsfxQ8pmX6tC9sTsD4iKr0YrPWb0G/T9nd0V55VVfpN6reBobs2PLNd59NcZtW9QPaG\nxOGSBpM9PyqPx4BaSSdAdtpL0pFV1rkb+NPUfgw7P7vqrXTqzKwwDhOzKiLiLeAKsgvjvwB+k3N7\nb5JdOL9a0kNkb1g8scpqPyQLoIeBS4GHgVfTsrnAw5JuzDMuszz8bC6zPkDSAGBgRGyXdDBwB3Bo\nCiazwvmaiVnfsAewMp3OEnCRg8R2Jz4yMetmkuaQffek1A8i4l+LGI9Zb3CYmJlZbr4Ab2ZmuTlM\nzMwsN4eJmZnl5jAxM7Pc/j9eaugNkvzRDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c02aa5470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_stat.plot.bar(x=\"url_length\", y=\"row_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------+----+----+--------------------+----------------+------------+\n",
      "|            ip|     timestamp|                 url|size|code|                  ua|          region|      domain|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+----------------+------------+\n",
      "|197.72.248.141|20140101020306|http://news.mail....|1412| 203|Safari/5.0 (compa...|Zabaykalsky Krai|news.mail.ru|\n",
      "|197.72.248.141|20140101020306|http://news.mail....|1412| 203|Safari/5.0 (compa...|  Stavropol Krai|news.mail.ru|\n",
      "|197.72.248.141|20140101020306|http://news.mail....|1412| 203|Safari/5.0 (compa...|        Chechnya|news.mail.ru|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+----------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_domains = (\n",
    "    log_with_regions\n",
    "    .withColumn(\"domain\", F.regexp_extract(\"url\", \"http:\\/\\/(.*)\\/\", 1))\n",
    ")\n",
    "log_with_domains.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_length</th>\n",
       "      <th>domain</th>\n",
       "      <th>row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>1676363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>news.mail.ru</td>\n",
       "      <td>1644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>newsru.com</td>\n",
       "      <td>1639043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>news.yandex.ru</td>\n",
       "      <td>1638174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>news.rambler.ru</td>\n",
       "      <td>1617023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_length           domain  row_count\n",
       "0          23         lenta.ru    1676363\n",
       "1          27     news.mail.ru    1644000\n",
       "2          25       newsru.com    1639043\n",
       "3          29   news.yandex.ru    1638174\n",
       "4          30  news.rambler.ru    1617023"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_stat = (\n",
    "    log_with_domains\n",
    "    .groupBy(F.length(\"url\").alias(\"url_length\"), \"domain\")\n",
    "    .agg(F.count(\"*\").alias(\"row_count\"))\n",
    "    .orderBy(\"row_count\", ascending=False)\n",
    "    .toPandas()\n",
    ")\n",
    "length_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|url                    |\n",
      "+-----------------------+\n",
      "|http://lenta.ru/5276738|\n",
      "|http://lenta.ru/5276738|\n",
      "|http://lenta.ru/5276738|\n",
      "|http://lenta.ru/5276738|\n",
      "|http://lenta.ru/5276738|\n",
      "+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_domains[log_with_domains.domain == \"lenta.ru\"][[\"url\"]].show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Functions\n",
    "\n",
    "### Let us calculate correlation between url_length and domain type\n",
    "\n",
    "The function type of the UDF can be one of the following:\n",
    "+ **SCALAR**. A scalar UDF defines a transformation: One or more `pandas.Series` -> a `pandas.Series`. Scalar UDFs are used with `pyspark.sql.DataFrame.withColumn()` and `pyspark.sql.DataFrame.select()`\n",
    "+ **GROUPED_MAP**. A grouped map UDF defines transformation: a `pandas.DataFrame` -> a `pandas.DataFrame`. Grouped map UDFs are used with `pyspark.sql.GroupedData.apply()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(domain='news.rambler.ru'),\n",
       " Row(domain='news.yandex.ru'),\n",
       " Row(domain='newsru.com'),\n",
       " Row(domain='news.mail.ru'),\n",
       " Row(domain='lenta.ru')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_with_domains[[\"domain\"]].distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyspark.sql.functions' has no attribute 'pandas_udf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-3e2b09d7948f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Spark 2.3+, and pyarrow (can be installed with \"pip install\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegerType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_domain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     mapping = {\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyspark.sql.functions' has no attribute 'pandas_udf'"
     ]
    }
   ],
   "source": [
    "# Spark 2.3+, and pyarrow (can be installed with \"pip install\")\n",
    "\n",
    "@F.pandas_udf(types.IntegerType())\n",
    "def encode_domain(domains):\n",
    "    mapping = {\n",
    "        'lenta.ru': 0,\n",
    "        'newsru.com': 1,\n",
    "        'news.mail.ru': 2,\n",
    "        'news.yandex.ru': 3,\n",
    "        'news.rambler.ru': 4\n",
    "    }\n",
    "    return domains.apply(lambda x: mapping.get(x))\n",
    "\n",
    "\n",
    "log_with_domains.withColumn(\"domain_digit\", encode_domain(\"domain\")).show(2, vertical=True)\n",
    "\n",
    "(\n",
    "    log_with_domains\n",
    "    .withColumn(\"domain_encoded\", encode_domain(\"domain\"))\n",
    "    .withColumn(\"url_length\", F.length(\"url\"))\n",
    "    .corr(\"url_length\", \"domain_encoded\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fancy stuff: working with time\n",
    "\n",
    "Let us count number of days users visited our site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|     timestamp|\n",
      "+--------------+\n",
      "|20140101020306|\n",
      "|20140101020306|\n",
      "|20140101020306|\n",
      "+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_domains[[\"timestamp\"]].show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve 'unix_timestamp(`timestamp`, 'yyyyMMddHHmmss')' due to data type mismatch: argument 1 requires (string or date or timestamp) type, however, '`timestamp`' is of bigint type.;;\\n'Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318, domain#2028, unix_timestamp(timestamp#88L, yyyyMMddHHmmss) AS ts#2283]\\n+- Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318, regexp_extract(url#89, http:\\\\/\\\\/(.*)\\\\/, 1) AS domain#2028]\\n   +- Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318]\\n      +- Join Inner, (ip#87 = ip#1317)\\n         :- Repartition 4, true\\n         :  +- Relation[ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] csv\\n         +- BroadcastHint\\n            +- Relation[ip#1317,region#1318] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o574.withColumn.\n: org.apache.spark.sql.AnalysisException: cannot resolve 'unix_timestamp(`timestamp`, 'yyyyMMddHHmmss')' due to data type mismatch: argument 1 requires (string or date or timestamp) type, however, '`timestamp`' is of bigint type.;;\n'Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318, domain#2028, unix_timestamp(timestamp#88L, yyyyMMddHHmmss) AS ts#2283]\n+- Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318, regexp_extract(url#89, http:\\/\\/(.*)\\/, 1) AS domain#2028]\n   +- Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318]\n      +- Join Inner, (ip#87 = ip#1317)\n         :- Repartition 4, true\n         :  +- Relation[ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] csv\n         +- BroadcastHint\n            +- Relation[ip#1317,region#1318] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:91)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:83)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:290)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:290)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:289)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:307)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:305)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:287)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:266)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:276)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$1.apply(QueryPlan.scala:280)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:280)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$6.apply(QueryPlan.scala:285)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:285)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:83)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:128)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:52)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:63)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:2845)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1131)\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:1884)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-904f063c42e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_with_domains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ts\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munix_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"yyyyMMddHHmmss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \"\"\"\n\u001b[1;32m   1501\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve 'unix_timestamp(`timestamp`, 'yyyyMMddHHmmss')' due to data type mismatch: argument 1 requires (string or date or timestamp) type, however, '`timestamp`' is of bigint type.;;\\n'Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318, domain#2028, unix_timestamp(timestamp#88L, yyyyMMddHHmmss) AS ts#2283]\\n+- Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318, regexp_extract(url#89, http:\\\\/\\\\/(.*)\\\\/, 1) AS domain#2028]\\n   +- Project [ip#87, timestamp#88L, url#89, size#90, code#91, ua#92, region#1318]\\n      +- Join Inner, (ip#87 = ip#1317)\\n         :- Repartition 4, true\\n         :  +- Relation[ip#87,timestamp#88L,url#89,size#90,code#91,ua#92] csv\\n         +- BroadcastHint\\n            +- Relation[ip#1317,region#1318] csv\\n\""
     ]
    }
   ],
   "source": [
    "log_with_domains.withColumn(\"ts\", F.unix_timestamp(\"timestamp\", \"yyyyMMddHHmmss\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|            ip|        ts|\n",
      "+--------------+----------+\n",
      "|197.72.248.141|1388541786|\n",
      "|197.72.248.141|1388541786|\n",
      "|197.72.248.141|1388541786|\n",
      "+--------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_unixtimestamp = (\n",
    "    log_with_domains\n",
    "    .withColumn(\"ts\", F.unix_timestamp(F.col(\"timestamp\").cast(\"string\"), \"yyyyMMddHHmmss\"))\n",
    "    .drop(\"timestamp\", \"url\", \"size\", \"code\", \"ua\", \"region\", \"domain\")\n",
    ")\n",
    "\n",
    "log_with_unixtimestamp.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|            ip|              days|\n",
      "+--------------+------------------+\n",
      "|  3.183.113.77|115.00466435185184|\n",
      "|168.255.93.197|115.05512731481481|\n",
      "|222.131.187.37|115.40369212962963|\n",
      "|56.167.169.126|114.50332175925926|\n",
      "| 33.49.147.163|115.72543981481482|\n",
      "+--------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "log_with_unixtimestamp\n",
    "    .groupBy(\"ip\")\n",
    "    .agg(F.min(\"ts\").alias(\"begin\"), F.max(\"ts\").alias(\"end\"))\n",
    "    .select(\"ip\", (F.col(\"end\") - F.col(\"begin\")).alias(\"seconds_overall\"))\n",
    "    .select(\"ip\", (F.col(\"seconds_overall\") / 60.0 / 60.0 / 24.0).alias(\"days\"))\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window functions\n",
    "\n",
    "Let us count the amount of user's sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----+\n",
      "|          ip|        ts|count|\n",
      "+------------+----------+-----+\n",
      "|25.62.10.220|1388835012| 7020|\n",
      "|25.62.10.220|1388835012| 7020|\n",
      "|25.62.10.220|1388835012| 7020|\n",
      "|25.62.10.220|1388835012| 7020|\n",
      "|25.62.10.220|1388835012| 7020|\n",
      "|25.62.10.220|1388835012| 7020|\n",
      "|25.62.10.220|1388835012| 7020|\n",
      "|25.62.10.220|1388835012| 7020|\n",
      "|25.62.10.220|1388835012| 7020|\n",
      "|25.62.10.220|1388835012| 7020|\n",
      "+------------+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "(\n",
    "log_with_unixtimestamp\n",
    "    .select(\"ip\", \"ts\", F.count(\"*\").over(Window.partitionBy(\"ip\")).alias(\"count\"))\n",
    "    .orderBy(\"count\")\n",
    "    .show(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_window = Window.orderBy(\"ts\").partitionBy(\"ip\")\n",
    "user_window = Window.partitionBy(\"ip\").orderBy(\"ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+----------+----------+\n",
      "|          ip|        ts|row_number|       lag|      lead|\n",
      "+------------+----------+----------+----------+----------+\n",
      "|3.183.113.77|1388594462|         1|      null|1388594462|\n",
      "|3.183.113.77|1388594462|         2|1388594462|1388594462|\n",
      "|3.183.113.77|1388594462|         3|1388594462|1388594462|\n",
      "|3.183.113.77|1388594462|         4|1388594462|1388594462|\n",
      "|3.183.113.77|1388594462|         5|1388594462|1388594462|\n",
      "|3.183.113.77|1388594462|         6|1388594462|1388594462|\n",
      "|3.183.113.77|1388594462|         7|1388594462|1388594462|\n",
      "|3.183.113.77|1388594462|         8|1388594462|1388594462|\n",
      "|3.183.113.77|1388594462|         9|1388594462|1388594462|\n",
      "|3.183.113.77|1388594462|        10|1388594462|1388594462|\n",
      "+------------+----------+----------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    log_with_unixtimestamp.select(\n",
    "        \"ip\",\n",
    "        \"ts\",\n",
    "        F.row_number().over(user_window).alias(\"row_number\"),\n",
    "        F.lag(\"ts\").over(user_window).alias(\"lag\"),\n",
    "        F.lead(\"ts\").over(user_window).alias(\"lead\"),\n",
    "    )\n",
    "    .show(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|             ip|count|\n",
      "+---------------+-----+\n",
      "|  75.208.40.166| 1363|\n",
      "| 197.72.248.141| 1101|\n",
      "|  33.49.147.163|  993|\n",
      "| 222.131.187.37|  711|\n",
      "|135.124.143.193|  653|\n",
      "| 168.255.93.197|  589|\n",
      "| 56.167.169.126|  579|\n",
      "|   49.203.96.67|  526|\n",
      "|   49.105.15.79|  480|\n",
      "| 110.91.102.196|  362|\n",
      "|247.182.249.253|  270|\n",
      "| 231.119.88.198|  207|\n",
      "|   25.62.10.220|  152|\n",
      "| 181.217.177.35|  137|\n",
      "| 168.146.187.80|  104|\n",
      "|   3.183.113.77|   99|\n",
      "|    14.8.59.211|   57|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "log_with_unixtimestamp\n",
    "    .select(\"ip\", \"ts\", F.lead(\"ts\").over(user_window).alias(\"lead\"))\n",
    "    .select(\"ip\", \"ts\", (F.col(\"lead\") - F.col(\"ts\")).alias(\"diff\"))\n",
    "    .where(\"diff > 60 * 30 or diff IS NULL\")\n",
    "    .groupBy(\"ip\")\n",
    "    .count()\n",
    "    .orderBy(F.col(\"count\").desc())\n",
    "    .show(30)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.44 ms, sys: 2.55 ms, total: 3.99 ms\n",
      "Wall time: 18.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_with_unixtimestamp.coalesce(1).write.csv(\"log_with_unixtimestamp.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 ms, sys: 4.99 ms, total: 15.5 ms\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_with_unixtimestamp.write.csv(\"log_with_unixtimestamp_no_coal.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
